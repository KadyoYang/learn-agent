#!/usr/bin/env tsx
import { execSync } from 'child_process';

interface SystemInfo {
  hostMemory: number; // GB
  dockerMemory: number; // GB
  availableMemory: number; // GB
  currentModels: string[];
}

interface ModelRecommendation {
  name: string;
  size: string;
  memoryRequired: number; // GB
  description: string;
  recommended: boolean;
}

async function getSystemInfo(): Promise<SystemInfo> {
  try {
    // Ìò∏Ïä§Ìä∏ Î©îÎ™®Î¶¨ ÌôïÏù∏
    const hostMemOutput = execSync('sysctl hw.memsize', { encoding: 'utf-8' });
    const hostMemory = parseInt(hostMemOutput.split(':')[1].trim()) / 1024 / 1024 / 1024;

    // Docker Î©îÎ™®Î¶¨ ÌôïÏù∏
    const dockerInfo = execSync('docker info 2>&1 | grep "Total Memory"', { encoding: 'utf-8' });
    const dockerMemoryMatch = dockerInfo.match(/([\d.]+)\s*GiB/i);
    const dockerMemory = dockerMemoryMatch ? parseFloat(dockerMemoryMatch[1]) : 0;

    // Ïª®ÌÖåÏù¥ÎÑà ÏÇ¨Ïö© Í∞ÄÎä• Î©îÎ™®Î¶¨ ÌôïÏù∏
    const containerMem = execSync(
      'docker exec serina-ollama free -h 2>/dev/null | grep Mem || echo "0"',
      { encoding: 'utf-8' }
    );
    const availableMatch = containerMem.match(/available:\s*([\d.]+)\s*Gi/i);
    const availableMemory = availableMatch ? parseFloat(availableMatch[1]) : dockerMemory * 0.8;

    // ÌòÑÏû¨ Î™®Îç∏ Î™©Î°ù
    const modelsOutput = execSync('docker exec serina-ollama ollama list 2>&1', { encoding: 'utf-8' });
    const currentModels = modelsOutput
      .split('\n')
      .slice(1)
      .filter(line => line.trim())
      .map(line => line.split(/\s+/)[0])
      .filter(Boolean);

    return {
      hostMemory,
      dockerMemory,
      availableMemory,
      currentModels,
    };
  } catch (error) {
    console.error('ÏãúÏä§ÌÖú Ï†ïÎ≥¥ ÌôïÏù∏ Ïã§Ìå®:', error);
    return {
      hostMemory: 16,
      dockerMemory: 8,
      availableMemory: 6,
      currentModels: [],
    };
  }
}

function getRecommendations(availableMemory: number): ModelRecommendation[] {
  const recommendations: ModelRecommendation[] = [
    {
      name: 'qwen2.5:3b',
      size: '~2.0 GB',
      memoryRequired: 2.5,
      description: 'ÌïúÍµ≠Ïñ¥ ÏßÄÏõê Ïö∞Ïàò, ReAct ÏÑ±Îä• Ï¢ãÏùå, 3B Î™®Îç∏ Ï§ë ÏµúÍ≥†',
      recommended: availableMemory >= 2.5 && availableMemory < 4,
    },
    {
      name: 'phi3:mini',
      size: '~2.3 GB',
      memoryRequired: 2.5,
      description: 'Microsoft Í≤ΩÎüâ Î™®Îç∏, Îπ†Î•¥Í≥† Ìö®Ïú®Ï†Å',
      recommended: availableMemory >= 2.5 && availableMemory < 4,
    },
    {
      name: 'gemma:2b',
      size: '~1.7 GB',
      memoryRequired: 2.0,
      description: 'Í∞ÄÏû• ÏûëÏùå, ÌïòÏßÄÎßå ReAct ÏùºÍ¥ÄÏÑ± ÎÇÆÏùå',
      recommended: availableMemory < 2.5,
    },
    {
      name: 'gemma:7b',
      size: '~5.0 GB',
      memoryRequired: 6.4,
      description: 'ÏÑ±Îä• Ïö∞Ïàò, ReAct Ïûò Îî∞Î¶Ñ, Î©îÎ™®Î¶¨ ÎßéÏù¥ ÌïÑÏöî',
      recommended: availableMemory >= 6.4,
    },
    {
      name: 'llama3.1:8b',
      size: '~4.7 GB',
      memoryRequired: 6.0,
      description: 'ÏµúÏã† Í∏∞Îä•, Ï¢ãÏùÄ ÏÑ±Îä•',
      recommended: availableMemory >= 6.0 && availableMemory < 6.4,
    },
    {
      name: 'mistral:7b',
      size: '~4.1 GB',
      memoryRequired: 5.5,
      description: 'Í∑†ÌòïÏû°Ìûå ÏÑ±Îä•',
      recommended: availableMemory >= 5.5 && availableMemory < 6.0,
    },
  ];

  return recommendations.sort((a, b) => {
    if (a.recommended && !b.recommended) return -1;
    if (!a.recommended && b.recommended) return 1;
    return a.memoryRequired - b.memoryRequired;
  });
}

async function main() {
  console.log('\nüîç ÏãúÏä§ÌÖú Ï†ïÎ≥¥ ÌôïÏù∏ Ï§ë...\n');

  const systemInfo = await getSystemInfo();

  console.log('üìä ÏãúÏä§ÌÖú Ï†ïÎ≥¥:');
  console.log(`   Ìò∏Ïä§Ìä∏ Î©îÎ™®Î¶¨: ${systemInfo.hostMemory.toFixed(1)} GB`);
  console.log(`   Docker Ìï†Îãπ Î©îÎ™®Î¶¨: ${systemInfo.dockerMemory.toFixed(1)} GB`);
  console.log(`   ÏÇ¨Ïö© Í∞ÄÎä• Î©îÎ™®Î¶¨: ${systemInfo.availableMemory.toFixed(1)} GB`);
  console.log(`   ÌòÑÏû¨ Îã§Ïö¥Î°úÎìúÎêú Î™®Îç∏: ${systemInfo.currentModels.join(', ') || 'ÏóÜÏùå'}\n`);

  const recommendations = getRecommendations(systemInfo.availableMemory);
  const recommended = recommendations.find(r => r.recommended);

  console.log('üí° Î™®Îç∏ Ï∂îÏ≤ú:\n');

  if (recommended) {
    console.log(`‚úÖ Ï∂îÏ≤ú Î™®Îç∏: ${recommended.name}`);
    console.log(`   ÌÅ¨Í∏∞: ${recommended.size}`);
    console.log(`   ÌïÑÏöî Î©îÎ™®Î¶¨: ${recommended.memoryRequired} GB`);
    console.log(`   ÏÑ§Î™Ö: ${recommended.description}\n`);

    console.log('üìù .env ÌååÏùºÏóê Îã§ÏùåÏùÑ ÏÑ§Ï†ïÌïòÏÑ∏Ïöî:');
    console.log(`   OLLAMA_MODEL=${recommended.name}\n`);

    console.log('Îã§Ïö¥Î°úÎìú Î™ÖÎ†πÏñ¥:');
    console.log(`   pnpm ollama:pull ${recommended.name}\n`);
  } else {
    console.log('‚ö†Ô∏è  ÏÇ¨Ïö© Í∞ÄÎä•Ìïú Î©îÎ™®Î¶¨Í∞Ä Î∂ÄÏ°±Ìï©ÎãàÎã§.');
    console.log('   Docker Desktop Î©îÎ™®Î¶¨ Ìï†ÎãπÏùÑ ÎäòÎ¶¨Í±∞ÎÇò Îçî ÏûëÏùÄ Î™®Îç∏ÏùÑ ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî.\n');
  }

  console.log('üìã Î™®Îì† Î™®Îç∏ ÏòµÏÖò:\n');
  recommendations.forEach((model, index) => {
    const status = model.recommended ? '‚úÖ Ï∂îÏ≤ú' : systemInfo.availableMemory >= model.memoryRequired ? '‚úÖ Í∞ÄÎä•' : '‚ùå Î∂ÄÏ°±';
    console.log(`${index + 1}. ${model.name} (${model.size})`);
    console.log(`   ${status} - ÌïÑÏöî: ${model.memoryRequired} GB`);
    console.log(`   ${model.description}\n`);
  });
}

main().catch(console.error);

